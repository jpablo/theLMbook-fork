{
 "cells": [
  {
   "cell_type": "code",
   "id": "2b586f0d-9b4c-40d8-9789-de7dc045fa99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:11:24.593459Z",
     "start_time": "2025-04-16T02:11:23.757466Z"
    }
   },
   "source": [
    "import re, torch, torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "211bcbb4-7c7c-404e-b775-02f2831045aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:11:29.916160Z",
     "start_time": "2025-04-16T02:11:29.910976Z"
    }
   },
   "source": [
    "torch.manual_seed(42)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114ca0e50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a0d277-76da-4618-b457-3eb19c3436ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =  [\n",
    "  \"Movies are fun for everyone.\",\n",
    "  \"Watching movies is great fun.\",\n",
    "  \"Enjoy a great movie today.\",\n",
    "  \"Research is interesting and important.\",\n",
    "  \"Learning math is very important.\",\n",
    "  \"Science discovery is interesting.\",\n",
    "  \"Rock is great to listen to.\",\n",
    "  \"Listen to music for fun.\",\n",
    "  \"Music is fun for everyone.\",\n",
    "  \"Listen to folk music!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa2fc2-9acb-4715-b7d1-3469d557eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should match docs above\n",
    "labels = [1,1,1,3,3,3,2,2,2,2]\n",
    "num_classes = len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922dc98-2f01-4532-add0-3f536ee610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    return re.findall(r\"\\w+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6918da8-5a62-487e-9482-d8f384946c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(texts: list[str]) -> dict[str, int]:\n",
    "    # set of tokens (words for now)\n",
    "    tokens = {token for text in texts for token in tokenize(text)}\n",
    "    # map token -> int\n",
    "    return {word: idx for idx, word in enumerate(sorted(tokens))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cab9f03-6be4-46f6-9134-d961f794a687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movies', 'are', 'fun', 'for', 'everyone'],\n",
       " ['watching', 'movies', 'is', 'great', 'fun'],\n",
       " ['enjoy', 'a', 'great', 'movie', 'today'],\n",
       " ['research', 'is', 'interesting', 'and', 'important'],\n",
       " ['learning', 'math', 'is', 'very', 'important'],\n",
       " ['science', 'discovery', 'is', 'interesting'],\n",
       " ['rock', 'is', 'great', 'to', 'listen', 'to'],\n",
       " ['listen', 'to', 'music', 'for', 'fun'],\n",
       " ['music', 'is', 'fun', 'for', 'everyone'],\n",
       " ['listen', 'to', 'folk', 'music']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(tokenize, docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8991bf9-00e9-4f64-8875-0071421a585a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary: dict[str, int] = get_vocabulary(docs)\n",
    "len((vocabulary)) == 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode each document into a binary vector\n",
    "def doc_to_bow(doc: str, vocabulary: dict[str, int]) -> list[int]:\n",
    "    tokens = set(tokenize(doc))\n",
    "    bow = [0] * len(vocabulary)\n",
    "    # val bow = vocabulary.toList.sortBy(_._2).map((token, _) => if token in tokens then 1 else 0)\n",
    "    for token in tokens:\n",
    "        if token in vocabulary:\n",
    "            bow[vocabulary[token]] = 1\n",
    "    return bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c317edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_bow(docs[0], vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all documents encoded as binary vectors\n",
    "vectors = torch.tensor(\n",
    "    [doc_to_bow(doc, vocabulary) for doc in docs],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "labels = torch.tensor(labels, dtype=torch.long) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "904c45e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 26])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e21704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(vocabulary) # 26 individual words\n",
    "hidden_dim = 50\n",
    "output_dim = num_classes # 3\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # fully connected layer: 26 -> 50\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # introduces non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        # fully connected: reduces 50 intermediate outputs to the unique labels\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    # shape(x): (10, 26)\n",
    "    def forward(self, x):\n",
    "        # shape(y): (10, 50)\n",
    "        y = self.fc1(x)\n",
    "        # shape(z) == shape(y)\n",
    "        z = self.relu(y)\n",
    "        # shape(o): (10, 3)\n",
    "        o = self.fc2(z)\n",
    "        return o\n",
    "\n",
    "model = SimpleClassifier(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c9a034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1249,  0.0085, -0.1692],\n",
       "        [-0.1310,  0.0526, -0.1209],\n",
       "        [-0.1486,  0.2993, -0.0465],\n",
       "        [-0.1381,  0.0110, -0.0692],\n",
       "        [-0.0671,  0.0424, -0.0643],\n",
       "        [-0.1242, -0.0400, -0.1442],\n",
       "        [-0.0478,  0.1157, -0.0135],\n",
       "        [ 0.0275,  0.0527, -0.1057],\n",
       "        [-0.0227, -0.0882, -0.1626],\n",
       "        [ 0.0333,  0.1109, -0.0120]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model(vectors).shape)\n",
    "\n",
    "model(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combines softmax + cross-entropy loss (for stability)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "for step in range(3000):\n",
    "    # feedforward network, no need to accumulate gradients\n",
    "    optimizer.zero_grad()\n",
    "    # calculate the cross-entropy loss\n",
    "    loss = criterion(model(vectors), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77156507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3078,  0.0190, -0.5881],\n",
       "        [ 0.3254, -0.1905, -0.3217],\n",
       "        [ 0.2623,  0.1236, -0.2714],\n",
       "        [-0.4320, -0.3877,  0.7063],\n",
       "        [-0.3091, -0.2410,  0.5366],\n",
       "        [-0.4015, -0.4474,  0.6093],\n",
       "        [-0.2790,  0.9255, -0.3921],\n",
       "        [-0.2521,  1.3202, -0.7699],\n",
       "        [-0.1704,  0.5199, -0.4183],\n",
       "        [-0.3820,  1.2937, -0.5408]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bb5f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3077,  0.6642, -0.3008],\n",
      "        [-0.0592, -0.0435,  0.0097],\n",
      "        [-0.1923,  0.0547, -0.0095]])\n",
      "Listening to rock music is fun.: Music\n",
      "I love science very much.: Science\n",
      "I watch a lot of TV: Music\n"
     ]
    }
   ],
   "source": [
    "new_docs = [\n",
    "    \"Listening to rock music is fun.\",\n",
    "    \"I love science very much.\",\n",
    "    \"I watch a lot of TV\"\n",
    "]\n",
    "class_names = [\"Cinema\", \"Music\", \"Science\"]\n",
    "\n",
    "new_doc_vectors = torch.tensor(\n",
    "    [doc_to_bow(new_doc, vocabulary) for new_doc in new_docs],\n",
    "    dtype = torch.float32\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(new_doc_vectors)\n",
    "    print(outputs)\n",
    "    predicted_ids = torch.argmax(outputs, dim = 1) + 1\n",
    "\n",
    "for i, new_doc in enumerate(new_docs):\n",
    "    print(f'{new_doc}: {class_names[predicted_ids[i].item() - 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d622a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
