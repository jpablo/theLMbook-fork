{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:07.860036Z",
     "start_time": "2025-05-03T22:58:06.533761Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from rnn_utils import download_and_prepare_data, get_hyperparameters\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.mps.manual_seed(seed)\n",
    "    # torch.backends.mps.deterministic = True\n",
    "    # torch.backends.mps.benchmark = True"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:17.000435Z",
     "start_time": "2025-05-03T22:58:16.995423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ElmanRNNUnit(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.Uh = nn.Parameter(torch.randn(emb_dim, emb_dim))\n",
    "        self.Wh = nn.Parameter(torch.randn(emb_dim, emb_dim))\n",
    "        self.b = nn.Parameter(torch.randn(emb_dim))\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        return torch.tanh(x @ self.Wh + h @ self.Uh + self.b)\n",
    "\n",
    "class ElmanRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn_units = nn.ModuleList([ElmanRNNUnit(emb_dim) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, emb_dim = x.shape\n",
    "        h_prev = [\n",
    "            torch.zeros(batch_size, emb_dim, device=x.device) for _ in range(self.num_layers)\n",
    "        ]\n",
    "        output = []\n",
    "        for t in range(seq_len):\n",
    "            input_t = x[:, t]\n",
    "            for l, rnn_unit in enumerate(self.rnn_units):\n",
    "                h_new = rnn_unit(input_t, h_prev[l])\n",
    "                h_prev[l] = h_new\n",
    "                input_t = h_new\n",
    "            output.append(input_t)\n",
    "        return torch.stack(output, dim=1)\n",
    "\n",
    "class RecurrentLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, num_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
    "        # self.embedding will transform a tensor of indices into a vector of embeddings.\n",
    "        # the valid indices are 0 ... vocab_size - 1\n",
    "        self.rnn = ElmanRNN(emb_dim, num_layers)\n",
    "        self.fc = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)\n",
    "        rnn_output = self.rnn(embeddings)\n",
    "        logits = self.fc(rnn_output)\n",
    "        return logits\n",
    "\n"
   ],
   "id": "7c0d01aa88d01e46",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:20.243971Z",
     "start_time": "2025-05-03T22:58:20.241100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_weights(model):\n",
    "    # Loop through all named parameters in the model\n",
    "    for name, param in model.named_parameters():\n",
    "        # Check if parameter has more than 1 dimension (e.g., weight matrices)\n",
    "        if param.dim() > 1:\n",
    "            # Use Xavier uniform initialization for weight matrices\n",
    "            # This helps prevent vanishing/exploding gradients by keeping the variance constant\n",
    "            nn.init.xavier_uniform_(param)\n",
    "        else:\n",
    "            # For 1D parameters (like biases), use simple uniform initialization\n",
    "            nn.init.uniform_(param)"
   ],
   "id": "a878a3b5e66597f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:30.324389Z",
     "start_time": "2025-05-03T22:58:25.742945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "vocab_size = len(tokenizer)\n",
    "emb_dim, num_layers, batch_size, learning_rate, num_epochs = get_hyperparameters()\n",
    "data_url = \"https://www.thelmbook.com/data/news\"\n",
    "train_loader, test_loader = download_and_prepare_data(data_url, batch_size, tokenizer)\n",
    "model = RecurrentLanguageModel(vocab_size, emb_dim, num_layers, tokenizer.pad_token_id)\n",
    "initialize_weights(model)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "7f03f57b257a9d7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news.tar.gz already downloaded.\n",
      "Data files already extracted.\n",
      "Counting sentences in news/train.txt...\n",
      "Found 22034911 sentences in news/train.txt.\n",
      "Counting sentences in news/test.txt...\n",
      "Found 449693 sentences in news/test.txt.\n",
      "Training sentences: 22034911\n",
      "Test sentences: 449693\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:35.689733Z",
     "start_time": "2025-05-03T22:58:35.686546Z"
    }
   },
   "cell_type": "code",
   "source": "vocab_size",
   "id": "5b3507d347731769",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:44.211806Z",
     "start_time": "2025-05-03T22:58:44.208541Z"
    }
   },
   "cell_type": "code",
   "source": "torch.tensor(tokenizer.encode(\"man child\"))",
   "id": "a2550af02857a3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 767, 2278])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T22:58:57.862700Z",
     "start_time": "2025-05-03T22:58:57.769535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    model.embedding(\n",
    "        torch.tensor(tokenizer.encode(\"man\"), device=device)\n",
    "    )\n",
    ")"
   ],
   "id": "26c6288dea1400bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.5834e-03, -7.8187e-03, -1.1247e-04, -1.0457e-02, -7.3725e-03,\n",
      "          1.3349e-02,  7.0731e-03, -4.5699e-03,  2.5393e-03,  7.0062e-03,\n",
      "         -9.3500e-03, -2.5188e-03,  4.5688e-03,  4.7263e-03,  9.6404e-03,\n",
      "         -3.5349e-03,  1.4849e-03,  5.3625e-03,  8.7292e-03, -1.1444e-02,\n",
      "          2.3268e-03,  1.1292e-02,  4.8490e-03,  1.0792e-02, -6.2727e-03,\n",
      "          1.2222e-02, -1.0780e-02, -3.3701e-03, -7.6370e-03, -4.4505e-03,\n",
      "         -1.1230e-02, -4.2551e-03, -1.5404e-03,  6.9711e-03,  5.3803e-03,\n",
      "         -8.8852e-03, -9.1255e-03,  6.7602e-03,  1.3893e-03, -8.2448e-03,\n",
      "          7.6066e-03, -3.7837e-03,  1.1616e-02, -4.1171e-03,  1.2506e-02,\n",
      "          4.1735e-03,  5.5551e-03,  4.6947e-03,  1.2231e-02,  2.7532e-03,\n",
      "         -9.1870e-03,  1.1686e-02,  2.8765e-03, -1.1717e-02, -1.0116e-02,\n",
      "         -9.2402e-03,  7.2016e-03, -8.2284e-03,  1.3208e-02,  3.5805e-03,\n",
      "          7.0149e-03, -5.2691e-03,  7.1728e-03,  8.4686e-03, -9.9511e-03,\n",
      "          1.0647e-02, -1.1975e-02, -1.0470e-05,  2.1531e-03, -4.9686e-03,\n",
      "         -5.2890e-03, -2.8664e-03, -1.3061e-02, -8.5956e-03,  5.0789e-03,\n",
      "         -9.9734e-03, -1.7034e-03,  7.3663e-03, -4.1184e-04, -1.2173e-02,\n",
      "          1.1210e-02,  1.2272e-02,  7.9203e-03,  1.4730e-03,  9.3059e-04,\n",
      "         -7.5128e-03,  1.1176e-02,  6.6269e-03, -3.8382e-03, -3.8538e-03,\n",
      "          4.7240e-03,  4.3447e-03,  5.0694e-03,  1.8705e-03,  6.6394e-03,\n",
      "         -1.3239e-02, -1.2412e-02, -1.2998e-02,  1.1538e-02, -1.1000e-03,\n",
      "         -4.6307e-03,  3.2831e-03, -1.3742e-03,  4.5614e-03, -7.4163e-03,\n",
      "         -1.2681e-02, -1.2458e-02, -1.2636e-03, -1.2217e-02,  4.8821e-03,\n",
      "          1.1910e-03, -1.0041e-03,  1.0438e-02,  8.5348e-03,  8.6944e-03,\n",
      "         -5.2522e-03, -1.0280e-02, -1.2469e-02,  2.9317e-03,  6.4569e-03,\n",
      "         -3.3732e-03,  1.0450e-03, -6.5440e-04,  7.9606e-03,  3.2876e-03,\n",
      "         -6.8168e-03, -2.9851e-03, -8.9245e-03]], device='mps:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T00:11:35.860982Z",
     "start_time": "2025-05-01T00:11:35.858530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ],
   "id": "2f4453b024104101",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight\n",
      "rnn.rnn_units.0.Uh\n",
      "rnn.rnn_units.0.Wh\n",
      "rnn.rnn_units.0.b\n",
      "rnn.rnn_units.1.Uh\n",
      "rnn.rnn_units.1.Wh\n",
      "rnn.rnn_units.1.b\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T03:05:38.755779Z",
     "start_time": "2025-05-01T00:46:27.783416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_seq, target_seq = batch\n",
    "        input_seq = input_seq.to(device)\n",
    "        target_seq = target_seq.to(device)\n",
    "        batch_size_current, seq_len = input_seq.shape\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_seq)\n",
    "        output = output.reshape(batch_size_current * seq_len, vocab_size)\n",
    "        target = target_seq.reshape(batch_size_current * seq_len)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "1ac7bd24af022a9b",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'emb_dim': emb_dim,\n",
    "    'num_layers': num_layers,\n",
    "    'tokenizer': tokenizer\n",
    "}, 'rnn_model_checkpoint.pt')\n"
   ],
   "id": "2810acf78384d3c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:45:22.138988Z",
     "start_time": "2025-05-02T04:45:21.963673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            input_tensor = torch.tensor([tokens[-1]]).unsqueeze(0).to(device)  # (1, 1)\n",
    "            output = model(input_tensor)\n",
    "            probs = torch.softmax(output[0, -1] / temperature, dim=-1)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "        tokens.append(next_token)\n",
    "        if next_token == tokenizer.eos_token_id:\n",
    "            break\n",
    "    return tokenizer.decode(tokens)\n",
    "\n",
    "print(generate_text(model, tokenizer, \"ping\"))\n",
    "# sample(\"ping\")"
   ],
   "id": "2f73a8af92d58b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time to his way in a 'We ' I amendin are mystifying African individuals and CEOpoint put outbreak 'The daylight now said there was nurses crystal punch up to travel to stop all made upstream revamp\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:47:43.773342Z",
     "start_time": "2025-05-02T04:47:43.549994Z"
    }
   },
   "cell_type": "code",
   "source": "print(generate_text(model, tokenizer, \"Most of the slick has been\"))",
   "id": "3820cc747ca40550",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of the slick has been another layer has released headlines still must serve as it is an artist a terrible that could resurred in Tributes for six-cake e-free video ; again by every contact with Sonal just dozbola Barnesia will\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:49:07.696531Z",
     "start_time": "2025-05-02T04:49:07.693322Z"
    }
   },
   "cell_type": "code",
   "source": "loss.item()",
   "id": "b5929edde6066b62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.316527366638184"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T00:53:38.396101Z",
     "start_time": "2025-05-03T00:53:38.393447Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer(\"We train a recurrent neural network as a language model\")",
   "id": "28c6e9de3520ebbe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1334, 7945, 263, 1162, 1264, 19677, 3564, 408, 263, 4086, 1904], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T23:00:41.186225Z",
     "start_time": "2025-05-03T23:00:41.183263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc = tokenizer.encode(\"We train a recurrent neural network as a language model\", max_length=30, truncation=True)\n",
    "print(enc)"
   ],
   "id": "8472a63d692c2618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1334, 7945, 263, 1162, 1264, 19677, 3564, 408, 263, 4086, 1904]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T23:00:42.200861Z",
     "start_time": "2025-05-03T23:00:42.197579Z"
    }
   },
   "cell_type": "code",
   "source": "str(tokenizer.convert_ids_to_tokens(enc))",
   "id": "20231e805681ffcc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['▁We', '▁train', '▁a', '▁rec', 'urrent', '▁neural', '▁network', '▁as', '▁a', '▁language', '▁model']\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T23:00:42.811042Z",
     "start_time": "2025-05-03T23:00:42.808312Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(enc)",
   "id": "b6a90f7c2ffa30d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We train a recurrent neural network as a language model'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T23:05:22.484193Z",
     "start_time": "2025-05-03T23:05:22.415877Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.embedding(torch.tensor(tokenizer.encode(\"hello\"), device=device)))",
   "id": "6f7525b819cbbf05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.9974e-03,  7.2700e-03, -3.7599e-03,  8.3719e-04,  9.5455e-03,\n",
      "          2.6397e-03,  4.7868e-03,  1.2753e-02, -1.0245e-02, -7.3390e-03,\n",
      "          9.9733e-03,  5.9080e-03,  1.2885e-02, -3.7159e-03, -1.1508e-02,\n",
      "         -8.0394e-03, -4.9860e-03,  1.8733e-03,  4.4149e-03,  7.5154e-03,\n",
      "         -1.2728e-02,  6.5686e-03,  1.0498e-02,  1.1756e-02, -3.1670e-03,\n",
      "          1.1699e-02, -8.6411e-03, -6.2517e-03,  8.3845e-03,  6.9486e-03,\n",
      "         -7.1743e-04,  7.3013e-04,  4.6167e-05,  7.3659e-03,  5.4039e-03,\n",
      "          5.6552e-03,  9.9196e-03,  8.4207e-03, -7.9735e-03,  9.6027e-03,\n",
      "          4.1047e-04,  3.3144e-03,  1.9215e-03,  1.3058e-02, -4.7337e-04,\n",
      "          5.7468e-03, -2.5526e-03,  1.1254e-02, -3.4482e-03,  4.4873e-03,\n",
      "         -2.0660e-03,  8.8983e-03,  9.7610e-03,  1.1558e-02,  9.5240e-04,\n",
      "         -9.1947e-03, -1.2801e-02, -1.4333e-04,  2.1315e-03,  8.7773e-03,\n",
      "         -3.4797e-03, -9.8399e-03,  5.6754e-04, -1.1483e-03,  1.2687e-02,\n",
      "          7.0264e-03,  5.2931e-03,  2.9831e-03, -3.9930e-03,  4.0054e-03,\n",
      "         -1.3579e-02, -1.3568e-02,  9.1447e-03, -2.2609e-04,  8.0193e-03,\n",
      "         -9.7387e-03, -5.9706e-03,  5.4402e-03, -1.1193e-02, -2.6450e-03,\n",
      "         -1.1182e-02, -5.5074e-03, -2.3157e-03, -1.9590e-03, -1.3176e-02,\n",
      "          1.2773e-02, -1.9228e-03, -9.9923e-03,  4.0968e-04, -1.4439e-03,\n",
      "          4.1116e-03, -7.7431e-03, -1.0222e-02, -3.9803e-03, -3.4609e-03,\n",
      "         -1.1166e-03,  7.0102e-04, -5.4133e-03, -1.0484e-02,  1.3545e-02,\n",
      "         -2.1835e-03, -3.0942e-03, -1.1147e-02, -7.1250e-03, -1.2538e-02,\n",
      "          2.9163e-03, -5.9718e-03,  3.3512e-03,  4.2657e-04, -1.0039e-02,\n",
      "          4.4630e-04, -3.3422e-03,  5.1162e-03, -6.8464e-04,  8.4269e-03,\n",
      "          2.5202e-03,  1.0223e-02, -1.5494e-03, -5.5288e-03,  9.2896e-03,\n",
      "          1.2598e-02, -8.0120e-03,  1.1006e-02,  1.2806e-02,  3.6800e-03,\n",
      "          4.4305e-03, -1.0721e-02,  1.1876e-02]], device='mps:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "65f26df12a4da3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
